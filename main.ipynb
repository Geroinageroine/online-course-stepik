{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "5BqiszGe-f1U"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from catboost import CatBoostClassifier, Pool #pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install catboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buyPSjUOAO2m",
        "outputId": "13dd8e81-9c44-4b80-bcbd-91f725f8af50"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.7/dist-packages (1.0.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from catboost) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.21.5)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from catboost) (3.2.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from catboost) (0.10.1)\n",
            "Requirement already satisfied: pandas>=0.24.0 in /usr/local/lib/python3.7/dist-packages (from catboost) (1.3.5)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.7/dist-packages (from catboost) (5.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from catboost) (1.15.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.24.0->catboost) (2018.9)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->catboost) (3.0.7)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.7/dist-packages (from plotly->catboost) (8.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mq9GUuS1-f1Z"
      },
      "source": [
        "### Предобработка данных (Вспомогательные функции используются в **Создании датасетов*)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "7oCsiW2b-f1b"
      },
      "outputs": [],
      "source": [
        "def time_filter(data, days=2):\n",
        "    \n",
        "    \"\"\"Фильтрация данных до порогового значения\"\"\"\n",
        "    \n",
        "    # создаем таблицу с первым и последним действием юзера\n",
        "    min_max_user_time = data.groupby('user_id').agg({'timestamp': 'min'}) \\\n",
        "                            .rename(columns={'timestamp': 'min_timestamp'}) \\\n",
        "                            .reset_index()\n",
        "    \n",
        "    data_time_filtered = pd.merge(data, min_max_user_time, on='user_id', how='outer')\n",
        "    \n",
        "    # отбираем те записи, которые не позднее двух дней с начала учебы\n",
        "    learning_time_threshold = days * 24 * 60 * 60\n",
        "    data_time_filtered = data_time_filtered.query(\"timestamp <= min_timestamp + @learning_time_threshold\")\n",
        "    \n",
        "    assert data_time_filtered.user_id.nunique() == data.user_id.nunique()\n",
        "    \n",
        "    return data_time_filtered.drop(['min_timestamp'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "6BH5C79O-f1c"
      },
      "outputs": [],
      "source": [
        "def base_features(events_data, submission_data):\n",
        "    \n",
        "    \"\"\"Создание датасета с базовыми фичами: действия юзера \n",
        "    и правильные\\неправильные ответы\"\"\"\n",
        "    \n",
        "    # построим таблицу со всеми действиями юзеров\n",
        "    users_events_data = pd.pivot_table(data=events_data, values='step_id',\n",
        "                                   index='user_id', columns='action',\n",
        "                                   aggfunc='count', fill_value=0) \\\n",
        "                                   .reset_index() \\\n",
        "                                   .rename_axis('', axis=1)\n",
        "    \n",
        "    # таблица с колво правильных и неправильных попыток\n",
        "    users_scores = pd.pivot_table(data=submission_data, \n",
        "                              values='step_id',\n",
        "                              index='user_id',\n",
        "                              columns='submission_status',\n",
        "                              aggfunc='count',\n",
        "                              fill_value=0).reset_index() \\\n",
        "                              .rename_axis('', axis=1)\n",
        "    \n",
        "    # соединяем в один датасет\n",
        "    users_data = pd.merge(users_scores, users_events_data, on='user_id', how='outer').fillna(0)\n",
        "    \n",
        "    assert users_data.user_id.nunique() == events_data.user_id.nunique()\n",
        "    \n",
        "    return users_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "H24SjRRl-f1d"
      },
      "outputs": [],
      "source": [
        "def target(submission_data, threshold=40):\n",
        "    \n",
        "    \"\"\"Вычисление целевой переменной. Если юзер сделал 40 практический заданий,\n",
        "    то будем считать, что он пройдет курс до конца\"\"\"\n",
        "    \n",
        "    # считаем колво решенных заданий у каждого пользователя\n",
        "    users_count_correct = submission_data[submission_data.submission_status == 'correct'] \\\n",
        "                .groupby('user_id').agg({'step_id': 'count'}) \\\n",
        "                .reset_index().rename(columns={'step_id': 'corrects'})\n",
        "    \n",
        "    # если юзер выполнил нужное колво заданий, то он пройдет курс до конца\n",
        "    users_count_correct['passed_course'] = (users_count_correct.corrects >= threshold).astype('int')\n",
        "    \n",
        "    return users_count_correct.drop(['corrects'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "M2DcO3Ys-f1e"
      },
      "outputs": [],
      "source": [
        "def time_features(events_data):\n",
        "    \n",
        "    \"\"\"Создание временных фичей\"\"\"\n",
        "    \n",
        "    # добавление колонок с датами\n",
        "    events_data['date'] = pd.to_datetime(events_data['timestamp'], unit='s')\n",
        "    events_data['day'] = events_data['date'].dt.date\n",
        "    \n",
        "    # создаем таблицу с первым\\последним действием юзера и колвом уникальных дней, проведенных на курсе\n",
        "    users_time_feature = events_data.groupby('user_id').agg({'timestamp': ['min', 'max'], 'day': 'nunique'}) \\\n",
        "                        .droplevel(level=0, axis=1) \\\n",
        "                        .rename(columns={'nunique': 'days'}) \\\n",
        "                        .reset_index()\n",
        "    \n",
        "    # добавление колонки с разницей между первым и последним появлением юзера,\n",
        "    # другими словами, сколько времени юзер потратил на прохождение в часах\n",
        "    users_time_feature['hours'] = round((users_time_feature['max'] - users_time_feature['min']) / 3600, 1)\n",
        "    \n",
        "    \n",
        "    return users_time_feature.drop(['max', 'min'], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "KpckRi0w-f1f"
      },
      "outputs": [],
      "source": [
        "def steps_tried(submission_data):\n",
        "    \n",
        "    \"\"\"Создание фичи с колвом уникальных шагов, которые пользователь пытался выполнить\"\"\"\n",
        "    \n",
        "    # сколько степов юзер попытался сделать\n",
        "    steps_tried = submission_data.groupby('user_id').step_id.nunique().to_frame().reset_index() \\\n",
        "                                        .rename(columns={'step_id': 'steps_tried'})\n",
        "    \n",
        "    return steps_tried"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "kY-nLQWw-f1g"
      },
      "outputs": [],
      "source": [
        "def correct_ratio(data):\n",
        "    \n",
        "    \"\"\"Создание фичи с долей правильных ответов\"\"\"\n",
        "    \n",
        "    data['correct_ratio'] = (data.correct / (data.correct + data.wrong)).fillna(0)\n",
        "    \n",
        "    return data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MTdrtIyE-f1h"
      },
      "source": [
        "### Создание датасетов"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "id": "3DgFz5bF-f1h"
      },
      "outputs": [],
      "source": [
        "def create_df(events_data, submission_data):\n",
        "    \n",
        "    \"\"\"функция для формирования X датасета и y с целевыми переменными\"\"\"\n",
        "    \n",
        "    # фильтруем данные по дням от начала учебы\n",
        "    events_2days = time_filter(events_data)\n",
        "    submissions_2days = time_filter(submission_data)\n",
        "    \n",
        "    # создаем таблицу с базовыми фичами\n",
        "    users_data = base_features(events_2days, submissions_2days)\n",
        "    \n",
        "    # создаем целевую переменную\n",
        "    users_target_feature = target(submission_data, threshold=40)\n",
        "    \n",
        "    # создаем таблицу с временными фичами\n",
        "    users_time_feature = time_features(events_2days)\n",
        "    \n",
        "    # создаем фичи с попытками степов и долей правильных ответов\n",
        "    users_steps_tried = steps_tried(submissions_2days)\n",
        "    users_data = correct_ratio(users_data)\n",
        "    \n",
        "    # соединяем шаги\n",
        "    first_merge = users_data.merge(users_steps_tried, how='outer').fillna(0)\n",
        "    \n",
        "    # соединяем фичи со временем\n",
        "    second_merge = first_merge.merge(users_time_feature, how='outer')\n",
        "    \n",
        "    # присоединяем целевую переменную\n",
        "    third_merge = second_merge.merge(users_target_feature, how='outer').fillna(0)\n",
        "    \n",
        "    # отделяем целевую переменную и удаляем ее из основного датасета\n",
        "    y = third_merge['passed_course'].map(int)\n",
        "    X = third_merge.drop(['passed_course'], axis=1)\n",
        "    \n",
        "    return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "yXK8xdRf-f1i"
      },
      "outputs": [],
      "source": [
        "def create_test_df(events_data, submission_data):\n",
        "    \n",
        "    \"\"\"функция для формирования test датасета без целевой переменной\"\"\"\n",
        "    \n",
        "    # фильтруем данные по дням от начала учебы\n",
        "    events_2days = time_filter(events_data)\n",
        "    submissions_2days = time_filter(submission_data)\n",
        "    \n",
        "    # создаем таблицу с базовыми фичами\n",
        "    users_data = base_features(events_2days, submissions_2days)\n",
        "    \n",
        "    \n",
        "    # создаем таблицу с временными фичами\n",
        "    users_time_feature = time_features(events_2days)\n",
        "    \n",
        "    # создаем фичи с попытками степов и долей правильных ответов\n",
        "    users_steps_tried = steps_tried(submissions_2days)\n",
        "    users_data = correct_ratio(users_data)\n",
        "    \n",
        "    # соединяем шаги\n",
        "    first_merge = users_data.merge(users_steps_tried, how='outer').fillna(0)\n",
        "    \n",
        "    # соединяем фичи со временем\n",
        "    X = first_merge.merge(users_time_feature, how='outer')\n",
        "       \n",
        "    return X"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wuf-ikK-f1i"
      },
      "source": [
        "### Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "pkQYavfk-f1j"
      },
      "outputs": [],
      "source": [
        "# загрузка тренировочного датасета\n",
        "events_data_train = pd.read_csv('/content/event_data_train.zip')\n",
        "submission_data_train = pd.read_csv('/content/submissions_data_train.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "HEqobYcQ-f1j"
      },
      "outputs": [],
      "source": [
        "# создание тренировочного датасета с нужными фичами и целевой переменной\n",
        "X_train, y = create_df(events_data_train, submission_data_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "H0seZvcS-f1k"
      },
      "outputs": [],
      "source": [
        "# загрузка тестового датасета\n",
        "events_data_test = pd.read_csv('/content/events_data_test.zip')\n",
        "submission_data_test = pd.read_csv('/content/submission_data_test.zip')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "zd04kPkN-f1k"
      },
      "outputs": [],
      "source": [
        "# создание тестового датасета\n",
        "X_test = create_test_df(events_data_test, submission_data_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCjLKSkT-f1k"
      },
      "source": [
        "### Обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "id": "xnjn8Xse-f1k"
      },
      "outputs": [],
      "source": [
        "def random_with_grid(train_data, y, size=0.20):\n",
        "    \n",
        "    \"\"\"Поиск наилучших параметров для RandomForest, обучаясь на тренировочной выборке.\n",
        "    Можно изменять или добавлять различные параметры. Может долго вычисляться.\"\"\"\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(train_data, y, test_size=size, random_state=42)\n",
        "    \n",
        "    param_grid = {'randomforestclassifier__n_estimators': range(20, 51, 3), \n",
        "                  'randomforestclassifier__max_depth': range(5, 14)}\n",
        "    \n",
        "    pipe = make_pipeline(RandomForestClassifier())\n",
        "    pipe.fit(X_train, y_train)\n",
        "    grid = GridSearchCV(pipe, param_grid=param_grid, cv=5, n_jobs=-1)\n",
        "    grid.fit(X_train, y_train)\n",
        "    print(f\"Наилучшие параметры: {grid.best_params_}\")\n",
        "    \n",
        "    ypred_prob = grid.predict_proba(X_test)\n",
        "    \n",
        "    roc_score = roc_auc_score(y_test, ypred_prob[:, 1])\n",
        "    score = grid.score(X_test, y_test)\n",
        "    print(f\"Правильность на тестовом наборе: {score:.2f}\")\n",
        "    print(roc_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "jHT_NFyp-f1l"
      },
      "outputs": [],
      "source": [
        "def random_final(train_data, y, test_data, size=0.20, Classifier = 1):\n",
        "    \n",
        "    \"\"\"Финальное обучение на тренировочном датасете с лучшими параметрами и \n",
        "    получением predict_proba для тестового датасета с записей в csv файл\"\"\"\n",
        "    \n",
        "    test_data = test_data.sort_values('user_id')\n",
        "    \n",
        "    X_train, X_test, y_train, y_test = train_test_split(train_data, y, test_size=size, random_state=42)\n",
        "    \n",
        "    if Classifier == 1:\n",
        "      pipe = make_pipeline(RandomForestClassifier(max_depth=7, n_estimators=40,  random_state=42))      \n",
        "    else:\n",
        "      pipe = make_pipeline(CatBoostClassifier(max_depth=7, n_estimators=40,  random_state=42,\n",
        "                           verbose=False))  \n",
        "\n",
        "    pipe.fit(X_train, y_train)\n",
        "    ypred_prob = pipe.predict_proba(X_test)\n",
        "    \n",
        "    roc_score = roc_auc_score(y_test, ypred_prob[:, 1])\n",
        "    score = pipe.score(X_test, y_test)\n",
        "    print(f\"Правильность на валид наборе: {score:.3f}\")\n",
        "    print(f\"Roc_auc_score на валид наборе: {roc_score:.5f}\")\n",
        "    \n",
        "    ypred_prob_final = pipe.predict_proba(test_data)\n",
        "    result = test_data['user_id'].to_frame()\n",
        "    result['is_gone'] = ypred_prob_final[:, 1]\n",
        "    result[['user_id', 'is_gone']].to_csv(f'my_predict_{roc_score:.5f}.csv', index=False)\n",
        "    print(f'Результы записанны в файл my_predict_{roc_score:.5f}.csv')\n",
        "    return roc_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wY9XlkUk-f1l"
      },
      "source": [
        "**Путем экспериментов выявленно, что фича hours уменьшает итоговую оценку. Выкидываем ее.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "GZ54dJSf-f1m"
      },
      "outputs": [],
      "source": [
        "def drop_feature(X_train, X_test, drop):\n",
        "    \n",
        "    \"\"\"Выкидываем выбранную фичу из обоих датасетов\"\"\"\n",
        "    \n",
        "    X_train_dropped = X_train.drop(drop, axis=1)\n",
        "    X_test_dropped = X_test.drop(drop, axis=1)\n",
        "    \n",
        "    return X_train_dropped, X_test_dropped"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "id": "41D9EyKc-f1m"
      },
      "outputs": [],
      "source": [
        "# удаляем фичу hours\n",
        "X_train_dropped, X_test_dropped = drop_feature(X_train, X_test, 'hours')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Финальное обучение и предсказание"
      ],
      "metadata": {
        "id": "UqcT6vlY_3cu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X-признаки:\", list(X_train_dropped.columns))\n",
        "print(\"y: юзер сделал 40 практический заданий\") "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUJmNDiDAqPu",
        "outputId": "b21137ab-a866-4255-dfbc-6765d6b6ae0c"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X-признаки: ['user_id', 'correct', 'wrong', 'discovered', 'passed', 'started_attempt', 'viewed', 'correct_ratio', 'steps_tried', 'days']\n",
            "y: юзер сделал 40 практический заданий\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_hTIej7o-f1m",
        "outputId": "4aadcec3-7f55-48d2-c124-e445c3f435d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Classifier\n",
            "Правильность на валид наборе: 0.900\n",
            "Roc_auc_score на валид наборе: 0.88471\n",
            "Результы записанны в файл my_predict_0.88471.csv\n"
          ]
        }
      ],
      "source": [
        "# финальное обучение и предсказание Random Forest\n",
        "print(\"Random Forest Classifier\")\n",
        "roc_score_RF = random_final(X_train_dropped, y, X_test_dropped, Classifier = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lIZWK1jz-f1o",
        "outputId": "27b1eb5e-8e93-4a6b-9445-693b60fa4016"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cat Boost (XGBoost) Classifier\n",
            "Правильность на валид наборе: 0.898\n",
            "Roc_auc_score на валид наборе: 0.88608\n",
            "Результы записанны в файл my_predict_0.88608.csv\n"
          ]
        }
      ],
      "source": [
        "# финальное обучение и предсказание Catboost\n",
        "print(\"Cat Boost (XGBoost) Classifier\")\n",
        "roc_score_CB = random_final(X_train_dropped, y, X_test_dropped, Classifier = 0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"CatBoostClassifier оказался лучше, чем RandomForestClassifier  {(roc_score_CB - roc_score_RF):.5f}\")\n",
        "print(f'Финальный roc_auc на тестовых {roc_score_CB:.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PWu5C7fkEZTf",
        "outputId": "44015d0a-e8e9-4392-e6af-fa72767666f0"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CatBoostClassifier оказался лучше, чем RandomForestClassifier  0.00137\n",
            "Финальный roc_auc на тестовых 0.88608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Финальный roc_auc на тестовых 0.88608**"
      ],
      "metadata": {
        "id": "eospLzfXGHGI"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}